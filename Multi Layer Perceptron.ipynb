{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Multi_Layer_Perceptron-3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqJhZoByy9_F"
      },
      "source": [
        "### **Importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lszdgeLpcMDU"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "torch.manual_seed(1)\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "import random\n",
        "random.seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWUbfO0-y9VE"
      },
      "source": [
        "# **1. Find the number of nodes in input and output layer according to the dataset and justify it in the report. Specify and justify any other hyper parameter that is/are needed.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZS4OFcq4c76"
      },
      "source": [
        "### **Function to read the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN7inasj4Ii5"
      },
      "source": [
        "def read_data():\n",
        "    '''\n",
        "        reads the dataset and returns a dataframe containing the required columns\n",
        "    '''\n",
        "    cols = ['lettr', 'x-box', 'y-box', 'width', 'high ', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
        "\n",
        "    df = pd.read_csv('letter-recognition.data', names=cols, header=None)\n",
        "\n",
        "    label = dict()\n",
        "    c = ord('A')\n",
        "    i = 0\n",
        "    \n",
        "    while c <= ord('Z'):\n",
        "        label[chr(c)] = i\n",
        "        c += 1\n",
        "        i += 1\n",
        "\n",
        "    df['lettr'].replace(label, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "data = read_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSkLPKhOM9XA"
      },
      "source": [
        "X = data.iloc[:, 1:]\n",
        "y = data['lettr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=15)\n",
        "\n",
        "scaling = StandardScaler() # MinMaxScaler()\n",
        "scaling.fit(X_train)\n",
        "\n",
        "X_train = scaling.transform(X_train)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "\n",
        "X_test = scaling.transform(X_test)\n",
        "X_test = pd.DataFrame(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG3fwrO7IWpb"
      },
      "source": [
        "train_target = torch.tensor(y_train.values.astype(np.int))\n",
        "train = torch.tensor(X_train.values.astype(np.float32))\n",
        "\n",
        "train_tensor = data_utils.TensorDataset(train, train_target)\n",
        "trainloader = data_utils.DataLoader(dataset=train_tensor, batch_size=128, shuffle=True)\n",
        "\n",
        "test_target = torch.tensor(y_test.values.astype(np.int))\n",
        "test = torch.tensor(X_test.values.astype(np.float32))\n",
        "\n",
        "test_tensor = data_utils.TensorDataset(test, test_target)\n",
        "testloader = data_utils.DataLoader(dataset=test_tensor, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izkLjoOY9k4K"
      },
      "source": [
        "learning_rates =  [0.1, 0.08, 0.05, 0.01, 0.001, 0.0001, 0.00001]\n",
        "model_accuracies = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqeySKaq8yA9"
      },
      "source": [
        "## **Class for Neural Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjjOJPhiSg9g"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_nodes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.n_layers = len(layer_nodes) - 1\n",
        "        for i in range(len(layer_nodes)-1):\n",
        "            layer_name = 'layer' + str(i)\n",
        "            setattr(self, layer_name, nn.Linear(layer_nodes[i], layer_nodes[i+1]))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        i = 0\n",
        "        while i < self.n_layers-1:\n",
        "            layer_name = 'layer' + str(i)\n",
        "            x = getattr(self, layer_name)(x)\n",
        "            x = F.relu(x)\n",
        "            i += 1\n",
        "        layer_name = 'layer' + str(i)\n",
        "        x = getattr(self, layer_name)(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWwpfjN549S5"
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, layers, learning_rate, epochs):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.model = NeuralNetwork(layers)\n",
        "        # Define the loss\n",
        "        self.criterion = nn.NLLLoss()\n",
        "        # Optimizers require the parameters to optimize and a learning rate\n",
        "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "    def fit(self, trainloader):\n",
        "        for e in range(self.epochs):\n",
        "            running_loss = 0\n",
        "            for features, labels in trainloader:\n",
        "                # features = features.view(-1, 16)\n",
        "            \n",
        "                # Training pass\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                output = self.model(features)\n",
        "                loss = self.criterion(output, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                running_loss += loss.item()\n",
        "\n",
        "            if (e+1)%100 == 0:\n",
        "                print(f\"Training loss after iteration {e+1}: {running_loss/len(trainloader)}\")\n",
        "\n",
        "    def accuracy(self, testloader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y in testloader:\n",
        "                output = self.model(X) # .view(-1, 16))\n",
        "                for idx, i in enumerate(output):\n",
        "                    if torch.argmax(i) == y[idx]:\n",
        "                        correct += 1\n",
        "                    total += 1\n",
        "        \n",
        "        return round(correct/total*100, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUTwf_CSAdtI"
      },
      "source": [
        "# **2. Vary the number of hidden layers and number of nodes in each hidden layer. Consider the following architectures.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQAVcAgkKhfl"
      },
      "source": [
        "## **Neural Network with 0 hidden layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgnFzj5XOVLf"
      },
      "source": [
        "model_accuracies['Model 1'] = dict()\n",
        "layer_nodes = [16, 26]\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    model1 = Model(layers=layer_nodes, learning_rate=learning_rate, epochs=1000)\n",
        "    model1.fit(trainloader)\n",
        "    model1_accuracy = model1.accuracy(testloader)\n",
        "    model_accuracies['Model 1'][learning_rate] = model1_accuracy\n",
        "    print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 1:', model1_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UYsxC3oMAQP"
      },
      "source": [
        "## **Neural Network with 1 hidden layer with 2 nodes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj2gnS6SCIZM"
      },
      "source": [
        "model_accuracies['Model 2'] = dict()\n",
        "layer_nodes = [16, 2, 26]\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    model2 = Model(layers=layer_nodes, learning_rate=learning_rate, epochs=1000)\n",
        "    model2.fit(trainloader)\n",
        "    model2_accuracy = model2.accuracy(testloader)\n",
        "    model_accuracies['Model 2'][learning_rate] = model2_accuracy\n",
        "    print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 2:', model2_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyXMaYn-MRVK"
      },
      "source": [
        "## **Neural Network with 1 hidden layer with 6 nodes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guOMIIo8EcTv"
      },
      "source": [
        "model_accuracies['Model 3'] = dict()\n",
        "layer_nodes = [16, 6, 26]\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    model3 = Model(layers=layer_nodes, learning_rate=learning_rate, epochs=1000)\n",
        "    model3.fit(trainloader)\n",
        "    model3_accuracy = model3.accuracy(testloader)\n",
        "    model_accuracies['Model 3'][learning_rate] = model3_accuracy\n",
        "    print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 3:', model3_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T9iHA6BMW_V"
      },
      "source": [
        "## **Neural Network with 2 hidden layers with 2 and 3 nodes respectively**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZl_fsNsEoLF"
      },
      "source": [
        "model_accuracies['Model 4'] = dict()\n",
        "layer_nodes = [16, 2, 3, 26]\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    model4 = Model(layers=layer_nodes, learning_rate=learning_rate, epochs=1000)\n",
        "    model4.fit(trainloader)\n",
        "    model4_accuracy = model4.accuracy(testloader)\n",
        "    model_accuracies['Model 4'][learning_rate] = model4_accuracy\n",
        "    print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 4:', model4_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hADrCBEzMa_b"
      },
      "source": [
        "## **Neural Network with 2 hidden layers with 3 and 2 nodes respectively**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6-SkdXaMifc"
      },
      "source": [
        "model_accuracies['Model 5'] = dict()\n",
        "layer_nodes = [16, 3, 2, 26]\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    model5 = Model(layers=layer_nodes, learning_rate=learning_rate, epochs=1000)\n",
        "    model5.fit(trainloader)\n",
        "    model5_accuracy = model5.accuracy(testloader)\n",
        "    model_accuracies['Model 5'][learning_rate] = model5_accuracy\n",
        "    print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 5:', model5_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed7eN28xZN1Y"
      },
      "source": [
        "## **Neural Network with 2 hidden layers with 14 and 22 nodes respectively**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGSYfCZBY684"
      },
      "source": [
        "model_accuracies['Model 6'] = dict()\n",
        "layer_nodes = [16, 14, 22, 26] \n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    model6 = Model(layers=layer_nodes, learning_rate=learning_rate, epochs=1000)\n",
        "    model6.fit(trainloader)\n",
        "    model6_accuracy = model6.accuracy(testloader)\n",
        "    model_accuracies['Model 6'][learning_rate] = model6_accuracy\n",
        "    print('Learning rate:', learning_rate, '\\tTest Accuracy for Model:', model6_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_54nbdu_6TY"
      },
      "source": [
        "## **Printing the Model Accuracies for Different Learning Rates**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg9oiLjGYjBm"
      },
      "source": [
        "models = []\n",
        "\n",
        "for model in model_accuracies:\n",
        "    print(model, ':', model_accuracies[model])\n",
        "    models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB35K3T-AK3g"
      },
      "source": [
        "# **3. Plot graph for the results in the previous parts with respect to accuracy. (Learning rate vs accuracy for each model (in one plot) and model vs accuracy for each learning rate (in one plot).)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn01v92u4kM5"
      },
      "source": [
        "for model in models:\n",
        "    x = [str(learning_rate) for learning_rate in learning_rates]\n",
        "    y = [model_accuracies[model][learning_rate] for learning_rate in learning_rates]\n",
        "    plt.plot(x, y, label=model)\n",
        "\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Rate VS Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7X72ZDw6atD"
      },
      "source": [
        "for learning_rate in learning_rates:\n",
        "    x = [model for model in models]\n",
        "    y = [model_accuracies[model][learning_rate] for model in models]\n",
        "    plt.plot(x, y, label=learning_rate)\n",
        "\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model VS Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdBvUYldCqS0"
      },
      "source": [
        "# **5. Reduce the feature dimension of the data into a two dimensional feature space using Principle Component Analysis (PCA). Plot the reduced dimensional data in a 2d plane. In the plot, all data points of a single class should have same color and data points from different classes should have different colors.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOLlWOcCNhxV"
      },
      "source": [
        "principal = PCA(n_components=2)\n",
        "principal.fit(X_train)\n",
        "\n",
        "X_train = principal.transform(X_train)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "\n",
        "X_test = principal.transform(X_test)\n",
        "X_test = pd.DataFrame(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54NPu9OtDKtB"
      },
      "source": [
        "train_target = torch.tensor(y_train.values.astype(np.int))\n",
        "train = torch.tensor(X_train.values.astype(np.float32))\n",
        "\n",
        "train_tensor = data_utils.TensorDataset(train, train_target)\n",
        "trainloader = data_utils.DataLoader(dataset=train_tensor, batch_size=128, shuffle=True)\n",
        "\n",
        "test_target = torch.tensor(y_test.values.astype(np.int))\n",
        "test = torch.tensor(X_test.values.astype(np.float32))\n",
        "\n",
        "test_tensor = data_utils.TensorDataset(test, test_target)\n",
        "testloader = data_utils.DataLoader(dataset=test_tensor, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq5LW_QFDeTw"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train, cmap='Set1')\n",
        "\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('Principal Component Analysis')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnupdCCfK92M"
      },
      "source": [
        "# **6. Apply MLP of step 2 in the reduced feature space. Compare with classification output generated from step 2. you may use best learning rate obtained from step 3.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6CR7xZ1LYu8"
      },
      "source": [
        "best_learning_rate = {'Model 1': 0.1, 'Model 2': 0.05, 'Model 3': 0.1, 'Model 4': 0.08, 'Model 5': 0.1, 'Model 6': 0.1}\n",
        "model_accuracies_PCA = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doaC5lt1MzlI"
      },
      "source": [
        "## **Neural Network with 0 hidden layer after applying PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRQvV2O1MxmJ"
      },
      "source": [
        "model_accuracies_PCA['Model 1'] = dict()\n",
        "layer_nodes = [2, 26]\n",
        "\n",
        "learning_rate=best_learning_rate['Model 1']\n",
        "model1 = Model(layers=layer_nodes, learning_rate=best_learning_rate['Model 1'], epochs=1000)\n",
        "model1.fit(trainloader)\n",
        "model1_accuracy = model1.accuracy(testloader)\n",
        "model_accuracies_PCA['Model 1'][learning_rate] = model1_accuracy\n",
        "print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 1:', model1_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkyw3zVSNywO"
      },
      "source": [
        "## **Neural Network with 1 hidden layer with 2 nodes after applying PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJdg9AT2N2b3"
      },
      "source": [
        "model_accuracies_PCA['Model 2'] = dict()\n",
        "layer_nodes = [2, 2, 26]\n",
        "\n",
        "learning_rate=best_learning_rate['Model 2']\n",
        "model2 = Model(layers=layer_nodes, learning_rate=best_learning_rate['Model 2'], epochs=1000)\n",
        "model2.fit(trainloader)\n",
        "model2_accuracy = model2.accuracy(testloader)\n",
        "model_accuracies_PCA['Model 2'][learning_rate] = model2_accuracy\n",
        "print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 2:', model2_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6vRNC5NOIi5"
      },
      "source": [
        "## **Neural Network with 1 hidden layer with 6 nodes after applying PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2Kk_l2KONW9"
      },
      "source": [
        "model_accuracies_PCA['Model 3'] = dict()\n",
        "layer_nodes = [2, 6, 26]\n",
        "\n",
        "learning_rate=best_learning_rate['Model 3']\n",
        "model3 = Model(layers=layer_nodes, learning_rate=best_learning_rate['Model 3'], epochs=1000)\n",
        "model3.fit(trainloader)\n",
        "model3_accuracy = model3.accuracy(testloader)\n",
        "model_accuracies_PCA['Model 3'][learning_rate] = model3_accuracy\n",
        "print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 3:', model3_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urVTDikNOgiZ"
      },
      "source": [
        "## **Neural Network with 2 hidden layers with 2 and 3 nodes respectively after applying PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk5vU7MQOi4O"
      },
      "source": [
        "model_accuracies_PCA['Model 4'] = dict()\n",
        "layer_nodes = [2, 2, 3, 26]\n",
        "\n",
        "learning_rate=best_learning_rate['Model 4']\n",
        "model4 = Model(layers=layer_nodes, learning_rate=best_learning_rate['Model 4'], epochs=1000)\n",
        "model4.fit(trainloader)\n",
        "model4_accuracy = model4.accuracy(testloader)\n",
        "model_accuracies_PCA['Model 4'][learning_rate] = model4_accuracy\n",
        "print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 4:', model4_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js0J5uW4Owzw"
      },
      "source": [
        "## **Neural Network with 2 hidden layers with 3 and 2 nodes respectively after applying PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnwZdgZDOznh"
      },
      "source": [
        "model_accuracies_PCA['Model 5'] = dict()\n",
        "layer_nodes = [2, 3, 2, 26]\n",
        "\n",
        "learning_rate=best_learning_rate['Model 5']\n",
        "model5 = Model(layers=layer_nodes, learning_rate=best_learning_rate['Model 5'], epochs=1000)\n",
        "model5.fit(trainloader)\n",
        "model5_accuracy = model5.accuracy(testloader)\n",
        "model_accuracies_PCA['Model 5'][learning_rate] = model5_accuracy\n",
        "print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 5:', model5_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ts7ojB0Z5UN"
      },
      "source": [
        "## **Neural Network with 2 hidden layers with 14 and 22 nodes respectively after applying PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILBkBK3AZ8bi"
      },
      "source": [
        "model_accuracies_PCA['Model 6'] = dict()\n",
        "layer_nodes = [2, 14, 22, 26]\n",
        "\n",
        "learning_rate=best_learning_rate['Model 6']\n",
        "model6 = Model(layers=layer_nodes, learning_rate=best_learning_rate['Model 6'], epochs=1000)\n",
        "model6.fit(trainloader)\n",
        "model6_accuracy = model6.accuracy(testloader)\n",
        "model_accuracies_PCA['Model 6'][learning_rate] = model6_accuracy\n",
        "print('Learning rate:', learning_rate, '\\tTest Accuracy for Model 6:', model6_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}